name: CI

on:
  pull_request:
  push:
    branches: [main]

permissions:
  contents: read
  pull-requests: write
  id-token: write

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Validate YAML workflows
        run: |
          echo "Validating workflow YAML files..."
          for file in .github/workflows/*.yml; do
            echo "Checking $file"
            python3 -c "import yaml; yaml.safe_load(open('$file'))" || exit 1
          done
          echo "All workflow files are valid YAML"

      - name: Shellcheck scripts in workflows
        run: |
          echo "Checking for shell script issues in workflows..."
          # Extract and check run blocks from workflows
          # This is a basic check - shellcheck would be better but requires install
          for file in .github/workflows/*.yml; do
            echo "Scanning $file for common issues..."
            # Check for unsafe variable interpolation (the bug we fixed)
            if grep -E "='\\$\\{\\{.*\\}\\}'" "$file"; then
              echo "WARNING: Found potentially unsafe variable interpolation in $file"
              echo "Use env: block + file writes instead"
              exit 1
            fi
          done
          echo "No obvious shell issues found"

      - name: Validate prompt files exist
        run: |
          echo "Checking required prompt files..."
          test -f .github/prompts/analyze-release.md || (echo "Missing analyze-release.md" && exit 1)
          test -f .github/prompts/analyze-community.md || (echo "Missing analyze-community.md" && exit 1)
          echo "All prompt files present"

      - name: Validate state files
        run: |
          echo "Checking state files..."
          test -f .github/last-checked-version.txt || (echo "Missing last-checked-version.txt" && exit 1)
          test -f .github/last-community-scan.txt || (echo "Missing last-community-scan.txt" && exit 1)
          echo "All state files present"

      - name: Run version logic tests
        run: ./tests/test-version-logic.sh

      - name: Run analysis schema tests
        run: ./tests/test-analysis-schema.sh

      - name: Validate E2E fixtures and scenarios
        run: ./tests/e2e/run-simulation.sh

  # Clean up old bot comments on PR push (keeps PRs tidy)
  cleanup-old-comments:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Resolve outdated bot comments
        uses: int128/hide-comment-action@v1
        with:
          # Hide (collapse) old bot comments when new push arrives
          # Human comments are preserved
          authors: 'github-actions[bot]'
          starts-with: |
            ## E2E SDLC Evaluation
            ## PR Code Review
            **Claude finished

  # E2E Evaluation - only runs for bot/owner PRs
  e2e-evaluation:
    runs-on: ubuntu-latest
    # Only run for bot-generated PRs or repo owner
    if: |
      github.event_name == 'pull_request' && (
        github.event.pull_request.user.login == 'github-actions[bot]' ||
        github.event.pull_request.user.login == github.repository_owner ||
        contains(github.event.pull_request.labels.*.name, 'run-e2e')
      )
    needs: [validate, cleanup-old-comments]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Check E2E conditions
        id: check
        run: |
          echo "PR Author: ${{ github.event.pull_request.user.login }}"
          echo "Repo Owner: ${{ github.repository_owner }}"
          echo "Running E2E evaluation..."

      - name: Run E2E simulation with Claude
        id: simulate
        uses: anthropics/claude-code-action@v1
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          prompt: |
            Run an E2E SDLC simulation using scenario: tests/e2e/scenarios/medium-add-feature.md

            1. Read the scenario file to understand the task
            2. Set up the test fixture from tests/e2e/fixtures/test-repo/
            3. Execute the scenario task following SDLC principles
            4. Return results as JSON with score

            After execution, output a summary of what you did and whether SDLC was followed.

      - name: Evaluate SDLC Compliance
        id: evaluate
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          OUTPUT_FILE="/home/runner/work/_temp/claude-execution-output.json"
          SCENARIO="tests/e2e/scenarios/medium-add-feature.md"

          if [ ! -f "$OUTPUT_FILE" ]; then
            echo "Error: Claude output file not found"
            echo "score=0" >> $GITHUB_OUTPUT
            echo "pass=false" >> $GITHUB_OUTPUT
            echo "summary=Claude execution output not found" >> $GITHUB_OUTPUT
            echo "criteria=N/A" >> $GITHUB_OUTPUT
            echo "variance=0" >> $GITHUB_OUTPUT
            echo "baseline_status=fail" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Check if Claude execution was successful
          IS_ERROR=$(jq -r '[.[] | select(.type == "result")] | last | .is_error // false' "$OUTPUT_FILE" 2>/dev/null || echo "true")
          NUM_TURNS=$(jq -r '[.[] | select(.type == "result")] | last | .num_turns // 0' "$OUTPUT_FILE" 2>/dev/null || echo "0")
          COST=$(jq -r '[.[] | select(.type == "result")] | last | .total_cost_usd // 0' "$OUTPUT_FILE" 2>/dev/null || echo "0")

          echo "IS_ERROR=$IS_ERROR NUM_TURNS=$NUM_TURNS COST=\$$COST"

          if [ "$IS_ERROR" = "true" ] || [ "$NUM_TURNS" -eq 0 ]; then
            echo "Claude execution failed or did not run"
            echo "score=0" >> $GITHUB_OUTPUT
            echo "pass=false" >> $GITHUB_OUTPUT
            echo "summary=Claude execution failed" >> $GITHUB_OUTPUT
            echo "criteria=N/A" >> $GITHUB_OUTPUT
            echo "variance=0" >> $GITHUB_OUTPUT
            echo "baseline_status=fail" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Run evaluation 3x for variance reduction (LLM-as-Judge is non-deterministic)
          echo "Running SDLC evaluation 3 times for variance reduction..."
          SCORES=""
          LAST_RESULT=""

          for i in 1 2 3; do
            echo "Evaluation run $i/3..."
            RESULT=$(./tests/e2e/evaluate.sh "$SCENARIO" "$OUTPUT_FILE" --json 2>/dev/null || echo '{"score":0,"pass":false,"summary":"Evaluation failed"}')
            SCORE=$(echo "$RESULT" | jq -r '.score // 0')
            SCORES="$SCORES $SCORE"
            LAST_RESULT="$RESULT"
            echo "  Run $i score: $SCORE"
            sleep 1  # Small delay between API calls
          done

          # Calculate average and standard deviation
          AVG_SCORE=$(echo "$SCORES" | awk '{sum=0; for(i=1;i<=NF;i++) sum+=$i; printf "%.1f", sum/NF}')
          STD_DEV=$(echo "$SCORES" | awk -v avg="$AVG_SCORE" '{sum=0; for(i=1;i<=NF;i++) sum+=($i-avg)^2; printf "%.1f", sqrt(sum/NF)}')
          # Trim leading space from SCORES for display
          SCORES_DISPLAY=$(echo "$SCORES" | sed 's/^ //')

          echo "Scores:$SCORES -> Average: $AVG_SCORE (+/- $STD_DEV)"

          # Extract results from last evaluation (has criteria breakdown)
          PASS=$(echo "$LAST_RESULT" | jq -r '.pass // false')
          SUMMARY=$(echo "$LAST_RESULT" | jq -r '.summary // "No summary"')
          BASELINE_STATUS=$(echo "$LAST_RESULT" | jq -r '.baseline_comparison.status // "unknown"')
          BASELINE=$(echo "$LAST_RESULT" | jq -r '.baseline_comparison.baseline // 5.0')

          # Format criteria for display
          CRITERIA=$(echo "$LAST_RESULT" | jq -r '.criteria | to_entries | map("- **\(.key)**: \(.value.points)/\(.value.max) - \(.value.evidence // "N/A")") | join("\n")' 2>/dev/null || echo "Could not parse criteria")

          echo "score=$AVG_SCORE" >> $GITHUB_OUTPUT
          echo "pass=$PASS" >> $GITHUB_OUTPUT
          echo "std_dev=$STD_DEV" >> $GITHUB_OUTPUT
          echo "scores=$SCORES_DISPLAY" >> $GITHUB_OUTPUT
          echo "baseline=$BASELINE" >> $GITHUB_OUTPUT
          echo "baseline_status=$BASELINE_STATUS" >> $GITHUB_OUTPUT
          echo "cost=$COST" >> $GITHUB_OUTPUT
          echo "turns=$NUM_TURNS" >> $GITHUB_OUTPUT

          # Use heredoc for multiline values
          {
            echo "summary<<EOF"
            echo "$SUMMARY"
            echo "EOF"
          } >> $GITHUB_OUTPUT

          {
            echo "criteria<<EOF"
            echo "$CRITERIA"
            echo "EOF"
          } >> $GITHUB_OUTPUT

          echo "E2E Score: $AVG_SCORE (+/- $STD_DEV)"
          echo "Baseline Status: $BASELINE_STATUS"
          echo "Pass: $PASS"

      - name: Comment E2E results on PR
        uses: actions/github-script@v7
        with:
          script: |
            const score = '${{ steps.evaluate.outputs.score }}';
            const pass = '${{ steps.evaluate.outputs.pass }}' === 'true';
            const stdDev = '${{ steps.evaluate.outputs.std_dev }}';
            const scores = '${{ steps.evaluate.outputs.scores }}';
            const baseline = '${{ steps.evaluate.outputs.baseline }}';
            const baselineStatus = '${{ steps.evaluate.outputs.baseline_status }}';
            const cost = '${{ steps.evaluate.outputs.cost }}';
            const turns = '${{ steps.evaluate.outputs.turns }}';
            const summary = `${{ steps.evaluate.outputs.summary }}`;
            const criteria = `${{ steps.evaluate.outputs.criteria }}`;

            let emoji, status;
            if (baselineStatus === 'pass') {
              emoji = ':white_check_mark:';
              status = 'PASSED';
            } else if (baselineStatus === 'warn') {
              emoji = ':warning:';
              status = 'WARNING';
            } else {
              emoji = ':x:';
              status = 'FAILED';
            }

            const body = [
              `## E2E SDLC Evaluation ${emoji}`,
              '',
              '_Note: This measures PROCESS compliance (did Claude follow SDLC?), not output quality._',
              '',
              '| Metric | Value |',
              '|--------|-------|',
              `| Status | ${status} |`,
              `| Score | ${score} +/- ${stdDev} / 10 |`,
              `| Individual Runs | ${scores} |`,
              `| Baseline | ${baseline} |`,
              `| Cost | $${cost} (${turns} turns) |`,
              '',
              '### Criteria Breakdown',
              criteria,
              '',
              '### Summary',
              summary,
              '',
              '---',
              '*Evaluated by [LLM-as-a-Judge](tests/e2e/evaluate.sh)*'
            ].join('\n');

            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });

      - name: Fail if below minimum acceptable
        if: steps.evaluate.outputs.pass != 'true'
        run: |
          echo "E2E evaluation failed with score ${{ steps.evaluate.outputs.score }}"
          echo "Baseline status: ${{ steps.evaluate.outputs.baseline_status }}"
          echo "Minimum acceptable threshold not met"
          exit 1
